{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“pytorch1.0_.ipynb”的副本",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcylmhlcy/Awesome-algorithm-interview/blob/master/pytorch1_0__ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhBqyqLfY8H5",
        "colab_type": "code",
        "outputId": "ddb01ba9-ac21-4483-993c-f35389f32ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 25 12:15:31 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    31W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S0v_fR9bsSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import os\n",
        "import shutil\n",
        "import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toXI2Ka7b82j",
        "colab_type": "code",
        "outputId": "75b641fc-de5b-4efe-b27b-1df7877c4aeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(torch.__version__)               # PyTorch version\n",
        "print(torch.version.cuda)              # Corresponding CUDA version\n",
        "print(torch.backends.cudnn.version())  # Corresponding cuDNN version\n",
        "print(torch.cuda.get_device_name(0))   # GPU type"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n",
            "10.0.130\n",
            "7402\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdSIuAH2fcGi",
        "colab_type": "code",
        "outputId": "5d95f5e0-f4c0-46ff-b31a-a2d3e99623f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 判断是否有cuda支持\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da2EE483fsg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 设置为 cuDNN benchmark 模式\n",
        "\n",
        "# Benchmark 模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# 如果想要避免这种结果波动，设置\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Note:\n",
        "# 总的来说，大部分情况下，设置这个 benchmark 可以让内置的 cuDNN 的 auto-tuner 自动寻找最适合当前配置的高效算法，来达到优化运行效率的问题。\n",
        "# 一般来讲，应该遵循以下准则：\n",
        "# (1)如果网络的输入数据维度或类型上变化不大，设置  torch.backends.cudnn.benchmark = true  可以增加运行效率；\n",
        "# (2)如果网络的输入数据在每次 iteration 都变化的话，会导致 cnDNN 每次都会去寻找一遍最优配置，这样反而会降低运行效率。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hy2HkZZfhah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 清除 GPU 存储\n",
        "\n",
        "# 有时 Control-C 中止运行后 GPU 存储没有及时释放，需要手动清空。在 PyTorch 内部可以\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 或在命令行可以先使用 ps 找到程序的 PID，再使用 kill 结束该进程\n",
        "ps aux | grep pythonkill -9 [pid]\n",
        "\n",
        "# 或者直接重置没有被清空的 GPU\n",
        "nvidia-smi --gpu-reset -i [gpu_id]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-MhivXle-Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 在训练开始时，参数的初始化是随机的，为了让每次的结果一致，我们需要设置随机种子。\n",
        "\n",
        "# 固定GPU随机化种子\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# 为CPU设置随机种子\n",
        "torch.manual_seed(args.seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGLRgYwH_Jpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pynvml\n",
        "pynvml.nvmlInit()\n",
        "import os\n",
        "\n",
        "# 查看当前显卡0，1的显存情况\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "print('GPU 0:', (meminfo.used) / 1024**3, 'G')\n",
        "\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(1)\n",
        "meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "print('GPU 1:', (meminfo.used) / 1024**3, 'G')\n",
        "\n",
        "# 打印目前显存\n",
        "print(os.system('nvidia-smi'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFhKbASJg3wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensor--------------------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiqSKstOhw3n",
        "colab_type": "code",
        "outputId": "ac59ba6c-c5ea-4b4a-82d4-53981d78e82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "a = torch.Tensor([[1,2,3],[4,5,6]])\n",
        "print(a.type())\n",
        "print(a.size())\n",
        "print(a.dim())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.FloatTensor\n",
            "torch.Size([2, 3])\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBkEzHtgmO8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set default tensor type. Float in PyTorch is much faster than double.\n",
        "torch.set_default_tensor_type(torch.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCPX7IUwmOAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Type convertions.\n",
        "a = a.cuda() # convert Tensor a on CPU to Tensor a on GPU\n",
        "a = a.cpu() # convert Tensor a on GPU to Tensor a on CPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15tfdr6lnyV7",
        "colab_type": "code",
        "outputId": "d6eb5d96-d9ba-4371-e834-33146515443a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "b = a.float() # convert a to FloatTensor\n",
        "print(b.type())\n",
        "c = a.long() # convert a to LongTensor\n",
        "print(c.type())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.FloatTensor\n",
            "torch.LongTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztJLcwAXoHwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.Tensor -> np.ndarray.\n",
        "a = a.cuda()\n",
        "a = a.cpu().numpy()  # convert to numpy on CPU\n",
        "\n",
        "# np.ndarray -> torch.Tensor.\n",
        "a1 = np.array([[1,2,3],[4,5,6]], dtype=np.int64)\n",
        "b1 = torch.from_numpy(ndarray).float()\n",
        "c1 = torch.from_numpy(ndarray.copy()).float()  # If ndarray has negative stride"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "567skuYBo33M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.Tensor 与 PIL.Image 转换\n",
        "# PyTorch 中的张量默认采用 N×D×H×W 的顺序，并且数据范围在 [0, 1]，需要进行转置和规范化。\n",
        "\n",
        "# torch.Tensor -> PIL.Image.\n",
        "image = PIL.Image.fromarray(torch.clamp(tensor * 255, min=0, max=255).byte().permute(1, 2, 0).cpu().numpy())\n",
        "image = torchvision.transforms.functional.to_pil_image(tensor)  # Equivalently way\n",
        "\n",
        "# PIL.Image -> torch.Tensor.\n",
        "tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))).permute(2, 0, 1).float() / 255\n",
        "tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))  # Equivalently way"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqA0VgBh3I0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.ndarray 与 PIL.Image 转换\n",
        "\n",
        "# np.ndarray -> PIL.Image.\n",
        "image = PIL.Image.fromarray(ndarray.astypde(np.uint8))\n",
        "\n",
        "# PIL.Image -> np.ndarray.\n",
        "ndarray = np.asarray(PIL.Image.open(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsQKUFj53XdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 从只包含一个元素的张量中提取值\n",
        "# 这在训练时统计 loss 的变化过程中特别有用。否则这将累积计算图，使 GPU 存储占用量越来越大。\n",
        "\n",
        "value = tensor.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AU7FWvI3fEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 张量形变\n",
        "# 张量形变常常需要用于将卷积层特征输入全连接层的情形。相比 torch.view，torch.reshape 可以自动处理输入张量不连续的情况。\n",
        "\n",
        "tensor = torch.reshape(tensor, shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bugXSOeg3ii5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # 打乱顺序\n",
        "\n",
        "tensor = tensor[torch.randperm(tensor.size(0))]  # Shuffle the first dimension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4pbyOxj3oKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 水平翻转\n",
        "# PyTorch 不支持 tensor[::-1] 这样的负步长操作，水平翻转可以用张量索引实现。\n",
        "\n",
        "# Assume tensor has shape N*D*H*W.\n",
        "tensor = tensor[:, :, :, torch.arange(tensor.size(3) - 1, -1, -1).long()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB1sg--g3u3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 复制张量\n",
        "# 有三种复制的方式，对应不同的需求。\n",
        "\n",
        "# Operation                 |  New/Shared memory | Still in computation graph |\n",
        "tensor.clone()            # |        New         |          Yes               |\n",
        "tensor.detach()           # |      Shared        |          No                |\n",
        "tensor.detach.clone()()   # |        New         |          No                |"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZUTmSWq3tTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 拼接张量\n",
        "# 注意 torch.cat 和 torch.stack 的区别在于 torch.cat 沿着给定的维度拼接，而 torch.stack 会新增一维。\n",
        "# 例如当参数是 3 个 10×5 的张量，torch.cat 的结果是 30×5 的张量，而 torch.stack 的结果是 3×10×5 的张量。\n",
        "\n",
        "tensor = torch.cat(list_of_tensors, dim=0)\n",
        "tensor = torch.stack(list_of_tensors, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIEfFDIp4WE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将整数标记转换成独热（one-hot）编码\n",
        "# PyTorch 中的标记默认从 0 开始。\n",
        "\n",
        "N = tensor.size(0)\n",
        "one_hot = torch.zeros(N, num_classes).long()\n",
        "one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KBd3rTT4dVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 得到非零/零元素\n",
        "\n",
        "torch.nonzero(tensor)               # Index of non-zero elements\n",
        "torch.nonzero(tensor == 0)          # Index of zero elements\n",
        "torch.nonzero(tensor).size(0)       # Number of non-zero elements\n",
        "torch.nonzero(tensor == 0).size(0)  # Number of zero elements"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML9QbG3_4gRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 张量扩展\n",
        "\n",
        "# Expand tensor of shape 64*512 to shape 64*512*7*7.\n",
        "torch.reshape(tensor, (64, 512, 1, 1)).expand(64, 512, 7, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ljTGrNY4jPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 矩阵乘法\n",
        "\n",
        "# Matrix multiplication: (m*n) * (n*p) -> (m*p).\n",
        "result = torch.mm(tensor1, tensor2)\n",
        "\n",
        "# Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p).\n",
        "result = torch.bmm(tensor1, tensor2)\n",
        "\n",
        "# Element-wise multiplication.\n",
        "result = tensor1 * tensor2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUzgFufG4m2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 计算两组数据之间的两两欧式距离\n",
        "\n",
        "# X1 is of shape m*d.\n",
        "X1 = torch.unsqueeze(X1, dim=1).expand(m, n, d)\n",
        "# X2 is of shape n*d.\n",
        "X2 = torch.unsqueeze(X2, dim=0).expand(m, n, d)\n",
        "# dist is of shape m*n, where dist[i][j] = sqrt(|X1[i, :] - X[j, :]|^2)\n",
        "dist = torch.sqrt(torch.sum((X1 - X2) ** 2, dim=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzqTARXi4rlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----模型定义------------------------------------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx6yJtN_4vrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 卷积层\n",
        "\n",
        "conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "# 如果卷积层配置比较复杂，不方便计算输出大小时，可以利用如下可视化工具辅助\n",
        "# 链接：https://ezyang.github.io/convolution-visualizer/index.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuRkoCjF8Viy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GAP（Global average pooling）层\n",
        "\n",
        "gap = torch.nn.AdaptiveAvgPool2d(output_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd5FMxLL8ZZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 双线性汇合（bilinear pooling）\n",
        "\n",
        "X = torch.reshape(N, D, H * W)                        # Assume X has shape N*D*H*W\n",
        "X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W)  # Bilinear pooling\n",
        "assert X.size() == (N, D, D)\n",
        "X = torch.reshape(X, (N, D * D))\n",
        "X = torch.sign(X) * torch.sqrt(torch.abs(X) + 1e-5)   # Signed-sqrt normalization\n",
        "X = torch.nn.functional.normalize(X)                  # L2 normalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itjmfksa89Wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 多卡同步 BN（Batch normalization）\n",
        "\n",
        "# 当使用 torch.nn.DataParallel 将代码运行在多张 GPU 卡上时，PyTorch 的 BN 层默认操作是各卡上数据独立地计算均值和标准差，\n",
        "# 同步 BN 使用所有卡上的数据一起计算 BN 层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，\n",
        "# 是在目标检测等任务中一个有效的提升性能的技巧。\n",
        "\n",
        "# 链接：https://github.com/vacancy/Synchronized-BatchNorm-PyTorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KStrD_Js9Miz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 类似 BN 滑动平均\n",
        "# 如果要实现类似 BN 滑动平均的操作，在 forward 函数中要使用原地（inplace）操作给滑动平均赋值。\n",
        "\n",
        "class BN(torch.nn.Module)\n",
        "    def __init__(self):\n",
        "        ...\n",
        "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
        "\n",
        "    def forward(self, X):\n",
        "        ...\n",
        "        self.running_mean += momentum * (current - self.running_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN9HdaTa9Slh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 计算模型整体参数量\n",
        "\n",
        "num_parameters = sum(torch.numel(parameter) for parameter in model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6YFvhsU9drJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 类似 Keras 的 model.summary() 输出模型信息\n",
        "\n",
        "# 链接：https://github.com/sksq96/pytorch-summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB-9Pjrh9kqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 模型权值初始化\n",
        "\n",
        "# 注意 model.modules() 和 model.children() 的区别：model.modules() 会迭代地遍历模型的所有子层，\n",
        "# 而 model.children() 只会遍历模型下的一层。\n",
        "\n",
        "# Common practise for initialization.\n",
        "for layer in model.modules():\n",
        "    if isinstance(layer, torch.nn.Conv2d):\n",
        "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',\n",
        "                                      nonlinearity='relu')\n",
        "        if layer.bias is not None:\n",
        "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
        "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
        "        torch.nn.init.constant_(layer.weight, val=1.0)\n",
        "        torch.nn.init.constant_(layer.bias, val=0.0)\n",
        "    elif isinstance(layer, torch.nn.Linear):\n",
        "        torch.nn.init.xavier_normal_(layer.weight)\n",
        "        if layer.bias is not None:\n",
        "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
        "\n",
        "# Initialization with given tensor.\n",
        "layer.weight = torch.nn.Parameter(tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHYm9Kui9s-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 部分层使用预训练模型\n",
        "\n",
        "# 注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是\n",
        "\n",
        "model.load_state_dict(torch.load('model,pth'), strict=False)\n",
        "\n",
        "\n",
        "# 读取整个网络\n",
        "model = torch.load(PATH)\n",
        "# 读取网络中的参数\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "# 读取网络中的部分参数（本质其实就是更新字典）\n",
        "pretrained_dict = torch.load(pretrained_model_weight)\n",
        "model_dict = model.state_dict()\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "model_dict.update(pretrained_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT6pDeergDdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 保存整个网络\n",
        "torch.save(model, PATH) \n",
        "# 保存网络中的参数, 速度快，占空间少\n",
        "torch.save(model.state_dict(),PATH)\n",
        "# 选择保存网络中的一部分参数或者额外保存其余的参数\n",
        "torch.save({'state_dict': model.state_dict(), 'fc_dict':model.fc.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),'alpha': loss.alpha, 'gamma': loss.gamma},\n",
        "             PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2-bQEgB9znQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将在 GPU 保存的模型加载到 CPU\n",
        "\n",
        "model.load_state_dict(torch.load('model,pth', map_location='cpu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak4lWDDRf50H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 加载完 Pre-Trained Model 后，我们需要对其进行 Finetune。但是在此之前，我们往往需要冻结一部分的模型参数：\n",
        "# 第一种方式\n",
        "for p in freeze.parameters(): # 将需要冻结的参数的 requires_grad 设置为 False\n",
        "    p.requires_grad = False\n",
        "for p in no_freeze.parameters(): # 将fine-tuning 的参数的 requires_grad 设置为 True\n",
        "    p.requires_grad = True\n",
        "# 将需要 fine-tuning 的参数放入optimizer 中\n",
        "optimizer.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
        "\n",
        "# 第二种方式\n",
        "optim_param = []\n",
        "for p in freeze.parameters(): # 将需要冻结的参数的 requires_grad 设置为 False\n",
        "    p.requires_grad = False\n",
        "for p in no_freeze.parameters(): # 将fine-tuning 的参数的 requires_grad 设置为 True\n",
        "    p.requires_grad = True\n",
        "    optim_param.append(p)\n",
        "optimizer.SGD(optim_param, lr=1e-3) # 将需要 fine-tuning 的参数放入optimizer 中"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjCbhqUN99K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----数据准备、特征提取与微调-----------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cyqrmo1-CnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 得到视频数据基本信息\n",
        "\n",
        "import cv2\n",
        "video = cv2.VideoCapture(mp4_path)\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVxKM7KH-Ifa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TSN 每段（segment）采样一帧视频\n",
        "\n",
        "K = self._num_segments\n",
        "if is_train:\n",
        "    if num_frames > K:\n",
        "        # Random index for each segment.\n",
        "        frame_indices = torch.randint(\n",
        "            high=num_frames // K, size=(K,), dtype=torch.long)\n",
        "        frame_indices += num_frames // K * torch.arange(K)\n",
        "    else:\n",
        "        frame_indices = torch.randint(\n",
        "            high=num_frames, size=(K - num_frames,), dtype=torch.long)\n",
        "        frame_indices = torch.sort(torch.cat((\n",
        "            torch.arange(num_frames), frame_indices)))[0]\n",
        "else:\n",
        "    if num_frames > K:\n",
        "        # Middle index for each segment.\n",
        "        frame_indices = num_frames / K // 2\n",
        "        frame_indices += num_frames // K * torch.arange(K)\n",
        "    else:\n",
        "        frame_indices = torch.sort(torch.cat((                              \n",
        "            torch.arange(num_frames), torch.arange(K - num_frames))))[0]\n",
        "assert frame_indices.size() == (K,)\n",
        "return [frame_indices[i] for i in range(K)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEfTktuG-MYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 提取 ImageNet 预训练模型某层的卷积特征\n",
        "\n",
        "# VGG-16 relu5-3 feature.\n",
        "model = torchvision.models.vgg16(pretrained=True).features[:-1]\n",
        "# VGG-16 pool5 feature.\n",
        "model = torchvision.models.vgg16(pretrained=True).features\n",
        "# VGG-16 fc7 feature.\n",
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:-3])\n",
        "# ResNet GAP feature.\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model = torch.nn.Sequential(collections.OrderedDict(\n",
        "    list(model.named_children())[:-1]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    conv_representation = model(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFagP3PE-smV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 提取 ImageNet 预训练模型多层的卷积特征\n",
        "\n",
        "class FeatureExtractor(torch.nn.Module):\n",
        "    \"\"\"Helper class to extract several convolution features from the given\n",
        "    pre-trained model.\n",
        "\n",
        "    Attributes:\n",
        "        _model, torch.nn.Module.\n",
        "        _layers_to_extract, list<str> or set<str>\n",
        "\n",
        "    Example:\n",
        "        >>> model = torchvision.models.resnet152(pretrained=True)\n",
        "        >>> model = torch.nn.Sequential(collections.OrderedDict(\n",
        "                list(model.named_children())[:-1]))\n",
        "        >>> conv_representation = FeatureExtractor(\n",
        "                pretrained_model=model,\n",
        "                layers_to_extract={'layer1', 'layer2', 'layer3', 'layer4'})(image)\n",
        "    \"\"\"\n",
        "    def __init__(self, pretrained_model, layers_to_extract):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self._model = pretrained_model\n",
        "        self._model.eval()\n",
        "        self._layers_to_extract = set(layers_to_extract)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            conv_representation = []\n",
        "            for name, layer in self._model.named_children():\n",
        "                x = layer(x)\n",
        "                if name in self._layers_to_extract:\n",
        "                    conv_representation.append(x)\n",
        "            return conv_representation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKJRRP6f-9ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 其他预训练模型\n",
        "\n",
        "# 链接：https://github.com/Cadene/pretrained-models.pytorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwQNdR21_BMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 微调全连接层\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc = nn.Linear(512, 100)  # Replace the last fc layer\n",
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A6Cxo7E_Erp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 以较大学习率微调全连接层，较小学习率微调卷积层\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "finetuned_parameters = list(map(id, model.fc.parameters()))\n",
        "conv_parameters = (p for p in model.parameters() if id(p) not in finetuned_parameters)\n",
        "parameters = [{'params': conv_parameters, 'lr': 1e-3}, \n",
        "              {'params': model.fc.parameters()}]\n",
        "optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxIh1UY2_HtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------模型训练------------------------------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRDXw4Nc_LNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 常用训练和验证数据预处理\n",
        "\n",
        "# 其中 ToTensor 操作会将 PIL.Image 或形状为 H×W×D，数值范围为 [0, 255] 的 np.ndarray 转换为形状为 D×H×W，\n",
        "# 数值范围为 [0.0, 1.0] 的 torch.Tensor。\n",
        "\n",
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomResizedCrop(size=224,\n",
        "                                             scale=(0.08, 1.0)),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                                     std=(0.229, 0.224, 0.225)),\n",
        " ])\n",
        " val_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(224),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                                     std=(0.229, 0.224, 0.225)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jdbSmX3_RrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 训练基本代码框架\n",
        "\n",
        "for t in epoch(80):\n",
        "    for images, labels in tqdm.tqdm(train_loader, desc='Epoch %3d' % (t + 1)):\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        scores = model(images)\n",
        "        loss = loss_function(scores, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u71jnNQq_U_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 标记平滑（label smoothing）\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    N = labels.size(0)\n",
        "    # C is the number of classes.\n",
        "    smoothed_labels = torch.full(size=(N, C), fill_value=0.1 / (C - 1)).cuda()\n",
        "    smoothed_labels.scatter_(dim=1, index=torch.unsqueeze(labels, dim=1), value=0.9)\n",
        "\n",
        "    score = model(images)\n",
        "    log_prob = torch.nn.functional.log_softmax(score, dim=1)\n",
        "    loss = -torch.sum(log_prob * smoothed_labels) / N\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqkJEgma_YXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mixup\n",
        "\n",
        "beta_distribution = torch.distributions.beta.Beta(alpha, alpha)\n",
        "for images, labels in train_loader:\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "    # Mixup images.\n",
        "    lambda_ = beta_distribution.sample([]).item()\n",
        "    index = torch.randperm(images.size(0)).cuda()\n",
        "    mixed_images = lambda_ * images + (1 - lambda_) * images[index, :]\n",
        "\n",
        "    # Mixup loss.    \n",
        "    scores = model(mixed_images)\n",
        "    loss = (lambda_ * loss_function(scores, labels) \n",
        "            + (1 - lambda_) * loss_function(scores, labels[index]))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzlygob4_a2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# L1 正则化\n",
        "\n",
        "l1_regularization = torch.nn.L1Loss(reduction='sum')\n",
        "loss = ...  # Standard cross-entropy loss\n",
        "for param in model.parameters():\n",
        "    loss += torch.sum(torch.abs(param))\n",
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "383WE2R9_eNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 不对偏置项进行 L2 正则化/权值衰减（weight decay）\n",
        "\n",
        "bias_list = (param for name, param in model.named_parameters() if name[-4:] == 'bias')\n",
        "others_list = (param for name, param in model.named_parameters() if name[-4:] != 'bias')\n",
        "parameters = [{'parameters': bias_list, 'weight_decay': 0},                \n",
        "              {'parameters': others_list}]\n",
        "optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLXmg2jA_g3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 梯度裁剪（gradient clipping）\n",
        "\n",
        "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrJyc-4c_jqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 计算 Softmax 输出的准确率\n",
        "\n",
        "score = model(images)\n",
        "prediction = torch.argmax(score, dim=1)\n",
        "num_correct = torch.sum(prediction == labels).item()\n",
        "accuruacy = num_correct / labels.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJkq3817_miI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 可视化模型前馈的计算图\n",
        "\n",
        "# 链接：https://github.com/szagoruyko/pytorchviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPVWPH1j_upP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 得到当前学习率\n",
        "\n",
        "# If there is one global learning rate (which is the common case).\n",
        "lr = next(iter(optimizer.param_groups))['lr']\n",
        "\n",
        "# If there are multiple learning rates for different layers.\n",
        "all_lr = []\n",
        "for param_group in optimizer.param_groups:\n",
        "    all_lr.append(param_group['lr'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Siww8sn__BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学习率衰减\n",
        "\n",
        "# Reduce learning rate when validation accuarcy plateau.\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)\n",
        "for t in range(0, 80):\n",
        "    train(...); val(...)\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "# Cosine annealing learning rate.\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80)\n",
        "# Reduce learning rate by 10 at given epochs.\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 70], gamma=0.1)\n",
        "for t in range(0, 80):\n",
        "    scheduler.step()    \n",
        "    train(...); val(...)\n",
        "\n",
        "# Learning rate warmup by 10 epochs.\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: t / 10)\n",
        "for t in range(0, 10):\n",
        "    scheduler.step()\n",
        "    train(...); val(...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shat9eotACKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 保存与加载断点\n",
        "\n",
        "# 注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。\n",
        "\n",
        "# Save checkpoint.\n",
        "is_best = current_acc > best_acc\n",
        "best_acc = max(best_acc, current_acc)\n",
        "checkpoint = {\n",
        "    'best_acc': best_acc,    \n",
        "    'epoch': t + 1,\n",
        "    'model': model.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "}\n",
        "model_path = os.path.join('model', 'checkpoint.pth.tar')\n",
        "torch.save(checkpoint, model_path)\n",
        "if is_best:\n",
        "    shutil.copy('checkpoint.pth.tar', model_path)\n",
        "\n",
        "# Load checkpoint.\n",
        "if resume:\n",
        "    model_path = os.path.join('model', 'checkpoint.pth.tar')\n",
        "    assert os.path.isfile(model_path)\n",
        "    checkpoint = torch.load(model_path)\n",
        "    best_acc = checkpoint['best_acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print('Load checkpoint at epoch %d.' % start_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HS1W431AHD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 计算准确率、查准率（precision）、查全率（recall）\n",
        "\n",
        "# data['label'] and data['prediction'] are groundtruth label and prediction \n",
        "# for each image, respectively.\n",
        "accuracy = np.mean(data['label'] == data['prediction']) * 100\n",
        "\n",
        "# Compute recision and recall for each class.\n",
        "for c in range(len(num_classes)):\n",
        "    tp = np.dot((data['label'] == c).astype(int),\n",
        "                (data['prediction'] == c).astype(int))\n",
        "    tp_fp = np.sum(data['prediction'] == c)\n",
        "    tp_fn = np.sum(data['label'] == c)\n",
        "    precision = tp / tp_fp * 100\n",
        "    recall = tp / tp_fn * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ7WlzBPAK70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------其它------------------------------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2PCkvOxASkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 模型定义\n",
        "\n",
        "# 建议有参数的层和汇合（pooling）层使用 torch.nn 模块定义，激活函数直接使用 torch.nn.functional。\n",
        "# torch.nn 模块和 torch.nn.functional 的区别在于，torch.nn 模块在计算时底层调用了 torch.nn.functional，\n",
        "# 但 torch.nn 模块包括该层参数，还可以应对训练和测试两种网络状态。使用 torch.nn.functional 时要注意网络状态，如\n",
        "\n",
        "def forward(self, x):\n",
        "    ...\n",
        "    x = torch.nn.functional.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "# model(x) 前用 model.train() 和 model.eval() 切换网络状态。\n",
        "\n",
        "# 不需要计算梯度的代码块用 with torch.no_grad() 包含起来。model.eval() 和 torch.no_grad() 的区别在于，\n",
        "# model.eval() 是将网络切换为测试状态，例如 BN 和随机失活（dropout）在训练和测试阶段使用不同的计算方法。\n",
        "# torch.no_grad() 是关闭 PyTorch 张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行 loss.backward()。\n",
        "\n",
        "# torch.nn.CrossEntropyLoss 的输入不需要经过 Softmax。torch.nn.CrossEntropyLoss 等价于 torch.nn.functional.log_softmax + torch.nn.NLLLoss。\n",
        "# loss.backward() 前用 optimizer.zero_grad() 清除累积梯度。optimizer.zero_grad() 和 model.zero_grad() 效果一样。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNnYOz4iAh89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PyTorch 性能与调试\n",
        "\n",
        "# torch.utils.data.DataLoader 中尽量设置 pin_memory=True，对特别小的数据集如 MNIST 设置 pin_memory=False 反而更快一些。\n",
        "# num_workers 的设置需要在实验中找到最快的取值。\n",
        "\n",
        "# 用 del 及时删除不用的中间变量，节约 GPU 存储。\n",
        "\n",
        "# 使用 inplace 操作可节约 GPU 存储，如\n",
        "\n",
        "x = torch.nn.functional.relu(x, inplace=True)\n",
        "\n",
        "\n",
        "# 减少 CPU 和 GPU 之间的数据传输。例如如果你想知道一个 epoch 中每个 mini-batch 的 loss 和准确率，\n",
        "# 先将它们累积在 GPU 中等一个 epoch 结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU 的传输更快。\n",
        "\n",
        "# 使用半精度浮点数 half() 会有一定的速度提升，具体效率依赖于 GPU 型号。需要小心数值精度过低带来的稳定性问题。\n",
        "\n",
        "# 时常使用 assert tensor.size() == (N, D, H, W) 作为调试手段，确保张量维度和你设想中一致。\n",
        "\n",
        "# 除了标记 y 外，尽量少使用一维张量，使用 n*1 的二维张量代替，可以避免一些意想不到的一维张量计算结果。\n",
        "\n",
        "# 统计代码各部分耗时\n",
        "\n",
        "with torch.autograd.profiler.profile(enabled=True, use_cuda=False) as profile:\n",
        "    ...\n",
        "print(profile)\n",
        "\n",
        "# 或者在命令行运行\n",
        "\n",
        "python -m torch.utils.bottleneck main.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxcveypAdlyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PyTorch中通过Dataloader加载图片，使用十分方便。但当加载图片较多并且需要做较多变换时，加载的速度很慢，\n",
        "# 会出现加载数据过慢（即使已经使用了多个worker），GPU空闲等待数据加载的情况。\n",
        "# ------------------------------------------------------------------------------------------------------------------\n",
        "# 1. 读取jpg图片加速\n",
        "#加载数据慢的一个很重要的原因的读取图片本身就比较慢，尤其是jpg图片解码更是耗时。\n",
        "# 如果你是读取jpg图片的话建议使用jpeg4py进行读取，只需要替换一行代码就搞定了。\n",
        "\n",
        "#具体的使用例子：\n",
        "import jpeg4py as jpeg\n",
        "import cv2\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    img_path = '1.jpg'\n",
        "    img = jpeg.JPEG(img_path).decode()\n",
        "    cv2.imshow('img', img)\n",
        "    cv2.waitKey(0)\n",
        "    \n",
        "# 解码出来的直接就是numpy数组，可以直接用opencv显示并进行相应的操作，但需要注意的是通道顺序是RGB，opencv默认的BGR。\n",
        "# 自己在小数据上测试了一下，使用opencv读取一个epoch需要7.5s，使用jpeg4py只需要3~4s，提速了近一倍。\n",
        "# https://github.com/ajkxyz/jpeg4py\n",
        "# ------------------------------------------------------------------------------------------------------------------\n",
        "# 2. 预取下一次迭代需要的数据\n",
        "# 提前预读数据，也是看了这篇文章得到的方法。\n",
        "# https://zhuanlan.zhihu.com/p/66145913\n",
        "\n",
        "# 一个使用的例子：\n",
        "\n",
        "class data_prefetcher():\n",
        "    def __init__(self, loader):\n",
        "        self.loader = iter(loader)\n",
        "        # self.stream = torch.cuda.Stream()\n",
        "        self.preload()\n",
        "\n",
        "    def preload(self):\n",
        "        try:\n",
        "            self.next_data = next(self.loader)\n",
        "        except StopIteration:\n",
        "            self.next_input = None\n",
        "            return\n",
        "        # with torch.cuda.stream(self.stream):\n",
        "        #     self.next_data = self.next_data.cuda(non_blocking=True)\n",
        "            \n",
        "    def next(self):\n",
        "        # torch.cuda.current_stream().wait_stream(self.stream)\n",
        "        data = self.next_data\n",
        "        self.preload()\n",
        "        return data\n",
        "\n",
        "###正常定义train_loader###\n",
        "\n",
        "prefetcher = data_prefetcher(train_loader)\n",
        "data = prefetcher.next()\n",
        "i = 0\n",
        "while data is not None:\n",
        "    print(i, len(data))\n",
        "    i += 1\n",
        "    data = prefetcher.next()\n",
        "    \n",
        "# 由于本地环境没有GPU，使用没有使用cuda，简单的使用预加载，速度可以从3.5s提高到2.25s。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jmQQbAvfBYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 利用 torch.nn.DataParallel 进行多 GPU 训练\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "# 生成模型\n",
        "# 利用 torch.nn.DataParallel 进行载入模型，默认使用所有GPU（可以用 CUDA_VISIBLE_DEVICES 设置所使用的 GPU）\n",
        "model = nn.DataParallel(models.resnet18())\n",
        "\n",
        "# 冻结参数\n",
        "for param in model.module.layer4.parameters():\n",
        "    param.requires_grad = False\n",
        "param_optim = filter(lambda p:p.requires_grad, model.parameters())\n",
        "\n",
        "# 设置测试模式\n",
        "model.module.layer4.eval()\n",
        "\n",
        "# 保存模型参数（读取所保存模型参数后，再进行并行化操作，否则无法利用之前的代码进行读取）\n",
        "torch.save(model.module.state_dict(),'./CheckPoint.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}